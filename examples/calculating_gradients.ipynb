{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating gradients with `SQcircuit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SQcircuit, you can easily compute the gradients of circuit properties including eigenfrequencies, decoherence times, and matrix elements with respect to the values of the circuit's elements. This notebook shows you how to do that.\n",
    "\n",
    "Make sure you've acquainted yourself with the basic operation of SQcircuit first (find a quick tutorial [here](https://docs.sqcircuit.org/quick_tutorial.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQcircuit performs almost all the gradient computation automatically. There are only two things you need to do differently when you want to compute gradients.\n",
    "\n",
    "### 1. Change the numerical engine of SQcircuit to PyTorch\n",
    "Normally, SQcircuit uses NumPy and QuTiP internally. However, to compute gradients we need to switch to using PyTorch (a machine-learning library). This is done using SQcircuit's `set_engine` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SQcircuit as sq\n",
    "sq.set_engine('PyTorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Indicate the elements to compute gradients with respect to\n",
    "\n",
    "When creating an element, you can decide if you need to compute gradients with respect to it. To do so, pass in the `requires_grad=True` argument. SQcircuit can compute gradients with respect to\n",
    "- Capacitors\n",
    "- Inductors\n",
    "- Junctions\n",
    "- Loops (i.e. external flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a flux-tunable transmon\n",
    "# We'll enable gradient computation for all the elements\n",
    "\n",
    "loop = sq.Loop(0.5, requires_grad=True)\n",
    "J1 = sq.Junction(1, 'GHz', loops=[loop], requires_grad=True)\n",
    "J2 = sq.Junction(2, 'GHz', loops=[loop], requires_grad=True)\n",
    "C = sq.Capacitor(0.5, 'GHz', requires_grad=True)\n",
    "\n",
    "circuit = sq.Circuit(\n",
    "    {(0, 1): [J1, J2, C]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can compute anything just like when using `SQcircuit` normally! For example, the qubit frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1861, dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "circuit.set_trunc_nums([60])\n",
    "circuit.diag(10)\n",
    "qubit_frequency =  circuit.efreqs[1] - circuit.efreqs[0]\n",
    "print(qubit_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing a property like the qubit frequency, we calculate the gradient of it with respect to the element values by calling `.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_frequency.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients can now be accessed via the `.grad` attribute of the elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of qubit frequency with respect to\n",
      "\t capacitor: tensor(-4.7772e+13, dtype=torch.float64)\n",
      "\t junction 1: tensor(-5.3377e-11, dtype=torch.float64)\n",
      "\t junction 2: tensor(5.3377e-11, dtype=torch.float64)\n",
      "\t external flux: tensor(5.8639e-08)\n"
     ]
    }
   ],
   "source": [
    "print('Gradients of qubit frequency with respect to')\n",
    "print('\\t capacitor:', C.grad)\n",
    "print('\\t junction 1:', J1.grad)\n",
    "print('\\t junction 2:', J2.grad)\n",
    "print('\\t external flux:', loop.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all there is to it! This works for just just about anything else that `SQcircuit` can compute.\n",
    "\n",
    "From decoherence times…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 time: tensor(0.0004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Gradients of T1 time with respect to\n",
      "\t capacitor: tensor(4.4872e+08, dtype=torch.float64)\n",
      "\t junction 1: tensor(1.1094e-13, dtype=torch.float64)\n",
      "\t junction 2: tensor(-1.1094e-13, dtype=torch.float64)\n",
      "\t external flux: tensor(-1.2188e-10)\n"
     ]
    }
   ],
   "source": [
    "circuit.zero_grad() # see Gotchas below\n",
    "\n",
    "t1 = 1 / (\n",
    "    circuit.dec_rate('capacitive', (0, 1))\n",
    "    + circuit.dec_rate('inductive', (0, 1))\n",
    "    + circuit.dec_rate('quasiparticle', (0, 1))\n",
    ")\n",
    "\n",
    "print('T1 time:', t1)\n",
    "\n",
    "t1.backward()\n",
    "\n",
    "print('Gradients of T1 time with respect to')\n",
    "print('\\t capacitor:', C.grad)\n",
    "print('\\t junction 1:', J1.grad)\n",
    "print('\\t junction 2:', J2.grad)\n",
    "print('\\t external flux:', loop.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "…to matrix elements like\n",
    "$$ g_{10} = \\frac{1}{C}|\\bra{1}{\\hat{Q}}\\ket{0}| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_{10}: tensor(2.4835e+11, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Gradients of g_{10} time with respect to\n",
      "\t capacitor: tensor(-1.4721e+24, dtype=torch.float64)\n",
      "\t junction 1: tensor(-30.4499, dtype=torch.float64)\n",
      "\t junction 2: tensor(30.4499, dtype=torch.float64)\n",
      "\t external flux: tensor(33451.8086)\n"
     ]
    }
   ],
   "source": [
    "circuit.zero_grad()\n",
    "\n",
    "import torch\n",
    "g_10 = (1/C.get_value()) * torch.abs(\n",
    "    circuit.evecs[1].conj()\n",
    "    @ circuit.charge_op(1)\n",
    "    @ circuit.evecs[0]\n",
    ")\n",
    "\n",
    "print('g_{10}:', g_10)\n",
    "\n",
    "g_10.backward()\n",
    "\n",
    "print('Gradients of g_{10} time with respect to')\n",
    "print('\\t capacitor:', C.grad)\n",
    "print('\\t junction 1:', J1.grad)\n",
    "print('\\t junction 2:', J2.grad)\n",
    "print('\\t external flux:', loop.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main applications of these gradients is to use during optimization. See the other [TODO] example notebook for a tutorial on how to do that from scratch, or use the ready-built [Qubit-Discovery](https://github.com/stanfordLINQS/Qubit-Discovery) module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gotchas\n",
    "\n",
    "Since SQcircuit uses PyTorch as a backend to compute gradients, there are a few things to be aware of if you haven't used PyTorch before.\n",
    "\n",
    "### 1. Gradients add unless cleared\n",
    "\n",
    "Suppose you calculate the gradient of the qubit frequency\n",
    "\n",
    "```\n",
    "qubit_frequency = circuit.efreqs[1] - circuit.efreqs[0]\n",
    "qubit_frequency.backward()\n",
    "```\n",
    "\n",
    "and then calculate the gradient of the $T_1$ time due to capacitive loss\n",
    "```\n",
    "T1 = circuit.dec_rate('capacitive', (0, 1))\n",
    "T1.backward()\n",
    "```\n",
    "\n",
    "The gradient of the elements will not be the gradient of just $T_1$, but instead the gradient of $T_1$ **plus** the gradient of $\\omega_{10}$. This is because every time you call `.backward()`, PyTorch adds the gradient on. \n",
    "\n",
    "To fix this, you must reset the gradients to zero. To do this, call the `.zero_grad()` method of the circuit. \n",
    "\n",
    "\n",
    "### 2. You can't call `.backward()` twice\n",
    "\n",
    "Suppose you compute the qubit frequency and compute the gradients by calling `.backward()` on it.\n",
    "\n",
    "```\n",
    "qubit_frequency = cr.efreqs[1] - cr.efreqs[0]\n",
    "qubit_frequency.backward()\n",
    "```\n",
    "\n",
    "If you need to recompute the gradient of `qubit_frequency` (for example, if you've zeroed the gradients in-between), calling `.backward()` on `qubit_frequency` again won't work. PyTorch automatically deletes some internal data after calling `.backward()` to save memory.\n",
    "\n",
    "Instead, you need to recompute the value, and then call\n",
    "```\n",
    "qubit_frequency = cr.efreqs[1] - cr.efreqs[0]\n",
    "qubit_frequency.backward()\n",
    "```\n",
    "\n",
    "If you know in advance you're going to need to recompute the gradient later, you can let PyTorch know by passing in `retain_graph=True` to `.backward()`.\n",
    "```\n",
    "qubit_frequency.backward(retain_graph=True)\n",
    "```\n",
    "\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "* Always call `circuit.zero_grad()` between calculating gradients of different functions.\n",
    "* Don't call `.backward()` twice on the same value; to recompute a gradient you must recompute the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
